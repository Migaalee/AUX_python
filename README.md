### Main_eML_aux_functions.py
This code was developed as part of my work on the eML project, where I focus on detecting low-frequency mutations from genomic data using Wolbachia population. 
The main goal of this code is to parse, process, and clean VCF files. The script handles various aspects of data imputation, expands rows with multi-valued columns, and calculates essential metrics for mutation analysis.
It is designed to preprocess data for downstream machine learning workflows.

-- expand_rows(df, column_to_expand, other_columns)
Expands rows in a DataFrame based on comma-separated values, creating individual rows for each alternative value.

-- parse_vcf_freebayes(fname, info_cols, parse_all_info)
Parses VCF files generated by FreeBayes, expanding alternative alleles and extracting key information from the INFO field.

-- parse_vcf_bcftools(fname, nrows)
Handles VCF files from BCFtools by converting the INFO column into key-value pairs, which are expanded into distinct columns for easier analysis.

-- parse_vcf_varscan(fname, info_cols, parse_all_info)
Reads VCF files from VarScan, extracting the relevant fields and separating multiple alternative alleles into their own rows.

-- confusion_matrix_m(dataset, gt_dataset, genome_size)
Computes a basic confusion matrix comparing dataset positions (POS) with ground truth, to assess true and false positives and negatives.

-- confusion_matrix_m1(dataset, gt_dataset, genome_size)
A more refined confusion matrix that also takes into account alternative alleles when comparing with ground truth data.

-- plot_custom_confusion_matrix(confusion_matrix, title)
Plots a customized confusion matrix for easy visualization of True Positives (TP), False Positives (FP), True Negatives (TN), and False Negatives (FN).

-- metrics_m(matrix, calculate)
Calculates key performance metrics—precision, recall, accuracy, and F1-score—from the confusion matrix.

-- TPR_FPR(dataset, gt_dataset, genome_size)
Computes True Positive Rate (TPR) and False Positive Rate (FPR) for mutation detection, helping evaluate model performance.

-- data_imputation(df, threshold_missing_data, imputation_methods)
Imputes missing values in the dataset based on user-defined methods (e.g., mean, median), keeping only columns with acceptable amounts of missing data.

-- data_imputation_median(df, threshold_missing_data)
Performs median imputation with random deviation for numeric columns with less than a specified percentage of missing values.

-- match_groudtruth(dataset, gt_dataset)
Matches a dataset with ground truth data by marking true variants with a "1" and false positives with a "0" to create a dataset ready for machine learning classification.
